{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00488187",
   "metadata": {},
   "source": [
    "# Haiku\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e1f473d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/parallels/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import requests  # To get the pages\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "import pyphen\n",
    "import syllapy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from statistics import mean\n",
    "# from bs4 import BeautifulSoup # and to process them\n",
    "\n",
    "con = sqlite3.connect(\"spam.db\")\n",
    "cur = con.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b76f8d",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006226ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://web.mit.edu/jync/www/spam/\"\n",
    "extension = \".html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe7cd5",
   "metadata": {},
   "source": [
    "## Scraper Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d52766",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = cur.execute(\"CREATE TABLE IF NOT EXISTS \\\"url_cache\\\" (\\\n",
    "\t\\\"hash\\\"\tTEXT,\\\n",
    "\t\\\"text\\\"\tTEXT\\\n",
    ");\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb871f",
   "metadata": {},
   "source": [
    "## Poem Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba587242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0xffffa00586c0>\n"
     ]
    }
   ],
   "source": [
    "# pt = cur.execute(\"DROP TABLE poems;\")\n",
    "\n",
    "pt = cur.execute(\"CREATE TABLE IF NOT EXISTS \\\"poems\\\" (\\\n",
    "\t\\\"id\\\"\tINTEGER UNIQUE,\\\n",
    "\t\\\"line_1\\\"\tTEXT,\\\n",
    "\t\\\"line_2\\\"\tTEXT,\\\n",
    "\t\\\"line_3\\\"\tTEXT,\\\n",
    "\t\\\"author\\\"\tTEXT\\\n",
    ");\")\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c226317",
   "metadata": {},
   "source": [
    "# Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dfd5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( 1001,19601,100 ) :\n",
    "    url = base_url + str(i) + \"-\" + str(i + 99) + extension\n",
    "    # print(url)\n",
    "    \n",
    "    ID = i\n",
    "    hash = hashlib.md5(url.encode()).hexdigest()\n",
    "    \n",
    "    # https://stackoverflow.com/a/9756276\n",
    "    res = cur.execute(\"SELECT EXISTS(SELECT 1 FROM url_cache WHERE hash='\"+hash+\"');\").fetchone()[0]\n",
    "    \n",
    "    if res is 0 :\n",
    "        r = requests.get(url)\n",
    "        text = r.text\n",
    "        cur.execute(\"INSERT INTO url_cache VALUES ( ?, ?)\", ( hash, text ) )\n",
    "        # print(hash)\n",
    "\n",
    "    else :\n",
    "        # print(hash)\n",
    "        continue \n",
    "        \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c6bd8",
   "metadata": {},
   "source": [
    "## Poem Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bda8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( 1001,19601,100 ) :\n",
    "    url = base_url + str(i) + \"-\" + str(i + 99) + extension\n",
    "    # print(url)\n",
    "    \n",
    "    ID = i\n",
    "    hash = hashlib.md5(url.encode()).hexdigest()\n",
    "    # print(hash)\n",
    "    res = cur.execute(\"SELECT text FROM url_cache WHERE `hash` = '\" + hash + \"'\" )\n",
    "    text = res.fetchone()[0]\n",
    "    \n",
    "    # print(len(text))\n",
    "    matches = re.findall(r\"<SPAN .*\\n.*\\n.*\\n.*\\n.*\\n.*\\n.*<P>\",text)\n",
    "    \n",
    "    for match in matches :\n",
    "        # Found some matches\n",
    "        # print( match )\n",
    "        groups = re.findall(r\"<SPAN CLASS='Number'>(.*)\\.</SPAN><BR>\\n.*\\n(.*)<BR>\\n(.*)<BR>\\n(.*)<BR>\\n.*\\n.*>--(.*)</ADDRESS><P>\", match)[0]\n",
    "        \n",
    "        if len( groups) == 5 :\n",
    "            # https://stackoverflow.com/a/4869782\n",
    "\n",
    "            poem_values = [ int(groups[0]), \n",
    "                           re.sub('<[^>]*>', '', groups[1]), \n",
    "                           re.sub('<[^>]*>', '', groups[2]),\n",
    "                           re.sub('<[^>]*>', '', groups[3]),\n",
    "                           re.sub('<[^>]*>', '', groups[4]),]\n",
    "            # print(poem_values)\n",
    "\n",
    "            insert_results = cur.execute(\"INSERT OR REPLACE INTO poems VALUES ( ?, ?, ?, ?, ? )\", poem_values )\n",
    "            # print(insert_results)\n",
    "        else :\n",
    "            pass\n",
    "            # print(len(groups))\n",
    "    # break\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629fee3",
   "metadata": {},
   "source": [
    "## Syllable Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c4a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pyphen.Pyphen(lang='en')\n",
    "# dic.inserted(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b7cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = syllapy.count('additional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8b1851ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_counts = defaultdict(list)\n",
    "invalid_words = list()\n",
    "all_words = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "697ea772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for poem in cur.execute(\"SELECT * FROM poems;\"):\n",
    "    first_line = 0\n",
    "    second_line = 0\n",
    "    third_line = 0\n",
    "\n",
    "    for word in re.sub(r'[^\\w\\s]', '', poem[1]).split() :\n",
    "        all_words.append(word.lower())\n",
    "        first_line += syllapy.count(word)\n",
    "        # record bad words\n",
    "        if syllapy.count(word) == 0 :\n",
    "            invalid_words.append(word)\n",
    "    for word in re.sub(r'[^\\w\\s]', '', poem[2]).split() :\n",
    "        second_line += syllapy.count(word)\n",
    "        all_words.append(word.lower())\n",
    "    for word in re.sub(r'[^\\w\\s]', '', poem[3]).split() :\n",
    "        third_line += syllapy.count(word)\n",
    "        all_words.append(word.lower())\n",
    "    \n",
    "#     print(first_line)\n",
    "#     print(second_line)\n",
    "#     print(third_line)\n",
    "    syllable_counts[poem[0]] = [first_line, second_line, third_line]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "992cd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllable_counts.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da10a3",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19b32f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums of all syllables\n",
      "93273\n",
      "131057\n",
      "93681\n",
      "Mins of all syllables\n",
      "0\n",
      "0\n",
      "0\n",
      "Maxs of all syllables\n",
      "8\n",
      "77\n",
      "22\n",
      "Avg of all syllables\n",
      "5.0147\n",
      "7.0461\n",
      "5.0366\n",
      "Valid Poems\n",
      "11299 out of 19601\n",
      "57.645% are valid\n",
      "Semi Valid Poems\n",
      "17795 out of 19601\n",
      "90.7862% are semi valid\n"
     ]
    }
   ],
   "source": [
    "first_lines = []\n",
    "second_lines = []\n",
    "third_lines = []\n",
    "\n",
    "valid = 0\n",
    "\n",
    "semi_valid = 0\n",
    "\n",
    "\n",
    "for poem in syllable_counts.items():\n",
    "    first_lines.append(poem[1][0])\n",
    "    second_lines.append(poem[1][1])\n",
    "    third_lines.append(poem[1][2])\n",
    "    # break\n",
    "    # print(type(poem[1][0]))\n",
    "\n",
    "    if poem[1][0] == 5 and \\\n",
    "    poem[1][1] == 7 and \\\n",
    "    poem[1][2] == 5 :\n",
    "        valid = valid + 1\n",
    "        \n",
    "    if poem[1][0] >= 4 and poem[1][0] <= 6 and \\\n",
    "    poem[1][1] >= 6 and poem[1][1] <= 8 and \\\n",
    "    poem[1][2] >= 4 and poem[1][2] <= 6 :\n",
    "        semi_valid = semi_valid + 1\n",
    "    \n",
    "print(\"Sums of all syllables\")\n",
    "print(sum(first_lines))  \n",
    "print(sum(second_lines))  \n",
    "print(sum(third_lines))  \n",
    "\n",
    "print(\"Mins of all syllables\")\n",
    "print(min(first_lines))  \n",
    "print(min(second_lines))  \n",
    "print(min(third_lines))  \n",
    "\n",
    "\n",
    "print(\"Maxs of all syllables\")\n",
    "print(max(first_lines))  \n",
    "print(max(second_lines))  \n",
    "print(max(third_lines))  \n",
    "\n",
    "print(\"Avg of all syllables\")\n",
    "print(round(mean(first_lines),4))  \n",
    "print(round(mean(second_lines),4))  \n",
    "print(round(mean(third_lines),4))  \n",
    "\n",
    "print(\"Valid Poems\")\n",
    "print( str(valid)+\" out of 19601\" )\n",
    "print( str(100*round(valid/19601,6))+\"% are valid\" )\n",
    "\n",
    "print(\"Semi Valid Poems\")\n",
    "print( str(semi_valid)+\" out of 19601\" )\n",
    "print( str(100*round(semi_valid/19601,6))+\"% are semi valid\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dae88d",
   "metadata": {},
   "source": [
    "## Naughty Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "46dc129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['95', 'NC-17:', \"'40s\", '8th', \"2's\", '13:', '/', '13', '5', '1st', 'MST3K:', '1984:', 'B-52', '486:', '911!']\n"
     ]
    }
   ],
   "source": [
    "print(invalid_words[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0437e",
   "metadata": {},
   "source": [
    "## Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f30b1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common All Words\n",
      "[('spam', 15338), ('the', 8381), ('a', 4836), ('i', 4630), ('of', 4357), ('in', 3672), ('and', 3624), ('is', 3146), ('to', 3099), ('my', 3080), ('it', 2924), ('you', 2218), ('can', 2152), ('on', 1881), ('for', 1812), ('pink', 1654), ('with', 1579), ('me', 1365), ('eat', 1308), ('not', 1193)]\n",
      "\n",
      "Most Common Filtered Words\n",
      "[('spam', 15338), ('pink', 1654), ('eat', 1308), ('like', 1100), ('meat', 1070), ('one', 655), ('blue', 605), ('love', 586), ('pig', 578), ('spamku', 507), ('hormel', 503), ('good', 477), ('pork', 473), ('food', 473), ('dont', 463), ('oh', 463), ('new', 390), ('man', 387), ('life', 385), ('haiku', 377)]\n"
     ]
    }
   ],
   "source": [
    "# Pass the split_it list to instance of Counter class.\n",
    "AllWordsCounter = Counter(all_words)\n",
    "  \n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "print(\"Most Common All Words\")\n",
    "print(AllWordsCounter.most_common(20))\n",
    "\n",
    "print()\n",
    "\n",
    "filtered_words = [t for t in all_words if not t in stopwords.words(\"english\")]\n",
    "\n",
    "# Pass the split_it list to instance of Counter class.\n",
    "FilteredWordsCounter = Counter(filtered_words)\n",
    "  \n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "print(\"Most Common Filtered Words\")\n",
    "print(FilteredWordsCounter.most_common(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88bda3",
   "metadata": {},
   "source": [
    "# Sample of Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "363b6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my mom brings home SPAM\n",
      "and i wonder what it is\n",
      "don't like the color\n",
      "\n",
      "SPAM and gossiping\n",
      "Are my twin pastimes of late\n",
      "Eat and ruin lives\n",
      "\n",
      "Turkey-shaped SPAM for\n",
      "Thanksgiving dinner. None give\n",
      "thanks but the turkey.\n",
      "\n",
      "Helping out the poor\n",
      "I offered the needy SPAM\n",
      "Bruises are healed now\n",
      "\n",
      "So many stories\n",
      "Sadness and joy of mankind\n",
      "Mingled in blue can\n",
      "\n",
      "General Motors\n",
      "Comes out with SPAM-powered car.\n",
      "Total sales: Zero.\n",
      "\n",
      "enigmatic brick\n",
      "Shackelton wished he had some\n",
      "expedition treat\n",
      "\n",
      "Encased in pectin...\n",
      "On that final sunny trot\n",
      "cold SPAM dwells in bliss.\n",
      "\n",
      "Sold Microsoft stock.\n",
      "With money, bought SPAM futures.\n",
      "The fools call me mad!\n",
      "\n",
      "SPAM is great camping.\n",
      "Fry it up in the pan with\n",
      "Leftover fish guts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for poem in cur.execute(\"SELECT * FROM poems ORDER BY random() LIMIT 10;\"):\n",
    "    print(poem[1])\n",
    "    print(poem[2])\n",
    "    print(poem[3])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "39033f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
