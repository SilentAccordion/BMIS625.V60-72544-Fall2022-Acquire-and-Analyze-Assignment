{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00488187",
   "metadata": {},
   "source": [
    "# Haiku\n",
    "\n",
    "## Background\n",
    "\n",
    "Traditional Haiku format consists of 3 lines of poetry, with a structure of 5 syllables, 7 syllables and 5 syllables.\n",
    "\n",
    "## Acquire\n",
    "\n",
    "We found a archive of over 20,000 potential haiku poems, based on a central theme.\n",
    "\n",
    "We wrote a short python script to download the collection, with consideration for the bandwidth of the host and stored them into a local SQLite DB.\n",
    "\n",
    "## Analyze\n",
    "\n",
    "Using the Python package `sullapy`, we did some statistical evaluation of the poem database, looking for valid haiku. \n",
    "\n",
    "## Results\n",
    "\n",
    "We found about 57% of poems in the collection could be evaluated as valid, based on the limitations of both the poets and `sullapy`. When we loosened up the definition of a haiku, to allow 4 to 6 syllables on the 1st and 3rd lines, and 6 to 8 on the 2nd line, we improved to 90% matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e1f473d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/parallels/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import requests  # To get the pages\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "import pyphen\n",
    "import syllapy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from statistics import mean\n",
    "# from bs4 import BeautifulSoup # and to process them\n",
    "\n",
    "con = sqlite3.connect(\"spam.db\")\n",
    "cur = con.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b76f8d",
   "metadata": {},
   "source": [
    "## Globals\n",
    "\n",
    "Setup the global variables needed to crawl the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006226ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://web.mit.edu/jync/www/spam/\"\n",
    "extension = \".html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe7cd5",
   "metadata": {},
   "source": [
    "## Scraper Table\n",
    "\n",
    "Setup a table in the SQLite DB for the results of the scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d52766",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = cur.execute(\"CREATE TABLE IF NOT EXISTS \\\"url_cache\\\" (\\\n",
    "\t\\\"hash\\\"\tTEXT,\\\n",
    "\t\\\"text\\\"\tTEXT\\\n",
    ");\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb871f",
   "metadata": {},
   "source": [
    "## Poem Table\n",
    "\n",
    "Setup a table in the SQLite DB for the extracted poems, or potential poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba587242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0xffffa00586c0>\n"
     ]
    }
   ],
   "source": [
    "# pt = cur.execute(\"DROP TABLE poems;\")\n",
    "\n",
    "pt = cur.execute(\"CREATE TABLE IF NOT EXISTS \\\"poems\\\" (\\\n",
    "\t\\\"id\\\"\tINTEGER UNIQUE,\\\n",
    "\t\\\"line_1\\\"\tTEXT,\\\n",
    "\t\\\"line_2\\\"\tTEXT,\\\n",
    "\t\\\"line_3\\\"\tTEXT,\\\n",
    "\t\\\"author\\\"\tTEXT\\\n",
    ");\")\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c226317",
   "metadata": {},
   "source": [
    "# Scraper\n",
    "\n",
    "Run the scraper, verifying if page has previously been scraped, and only scrap if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dfd5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( 1001,19601,100 ) :\n",
    "    url = base_url + str(i) + \"-\" + str(i + 99) + extension\n",
    "    # print(url)\n",
    "    \n",
    "    ID = i\n",
    "    hash = hashlib.md5(url.encode()).hexdigest()\n",
    "    \n",
    "    # https://stackoverflow.com/a/9756276\n",
    "    res = cur.execute(\"SELECT EXISTS(SELECT 1 FROM url_cache WHERE hash='\"+hash+\"');\").fetchone()[0]\n",
    "    \n",
    "    if res is 0 :\n",
    "        r = requests.get(url)\n",
    "        text = r.text\n",
    "        cur.execute(\"INSERT INTO url_cache VALUES ( ?, ?)\", ( hash, text ) )\n",
    "        # print(hash)\n",
    "\n",
    "    else :\n",
    "        # print(hash)\n",
    "        continue \n",
    "        \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c6bd8",
   "metadata": {},
   "source": [
    "## Poem Extractor\n",
    "\n",
    "Using a regular expression find all possible matches in the cached page content storing the matches into the poem table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bda8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( 1001,19601,100 ) :\n",
    "    url = base_url + str(i) + \"-\" + str(i + 99) + extension\n",
    "    # print(url)\n",
    "    \n",
    "    ID = i\n",
    "    hash = hashlib.md5(url.encode()).hexdigest()\n",
    "    # print(hash)\n",
    "    res = cur.execute(\"SELECT text FROM url_cache WHERE `hash` = '\" + hash + \"'\" )\n",
    "    text = res.fetchone()[0]\n",
    "    \n",
    "    # print(len(text))\n",
    "    matches = re.findall(r\"<SPAN .*\\n.*\\n.*\\n.*\\n.*\\n.*\\n.*<P>\",text)\n",
    "    \n",
    "    for match in matches :\n",
    "        # Found some matches\n",
    "        # print( match )\n",
    "        groups = re.findall(r\"<SPAN CLASS='Number'>(.*)\\.</SPAN><BR>\\n.*\\n(.*)<BR>\\n(.*)<BR>\\n(.*)<BR>\\n.*\\n.*>--(.*)</ADDRESS><P>\", match)[0]\n",
    "        \n",
    "        if len( groups) == 5 :\n",
    "            # https://stackoverflow.com/a/4869782\n",
    "\n",
    "            poem_values = [ int(groups[0]), \n",
    "                           re.sub('<[^>]*>', '', groups[1]), \n",
    "                           re.sub('<[^>]*>', '', groups[2]),\n",
    "                           re.sub('<[^>]*>', '', groups[3]),\n",
    "                           re.sub('<[^>]*>', '', groups[4]),]\n",
    "            # print(poem_values)\n",
    "\n",
    "            insert_results = cur.execute(\"INSERT OR REPLACE INTO poems VALUES ( ?, ?, ?, ?, ? )\", poem_values )\n",
    "            # print(insert_results)\n",
    "        else :\n",
    "            pass\n",
    "            # print(len(groups))\n",
    "    # break\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629fee3",
   "metadata": {},
   "source": [
    "## Syllable Counter\n",
    "\n",
    "Setting up the required tools to do the syllable counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c4a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pyphen.Pyphen(lang='en')\n",
    "# dic.inserted(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "27b7cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = syllapy.count('additional.')\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8b1851ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_counts = defaultdict(list)\n",
    "invalid_words = list()\n",
    "all_words = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb75890",
   "metadata": {},
   "source": [
    "Load all poems from database, and count syllables for each line of each poem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "697ea772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for poem in cur.execute(\"SELECT * FROM poems;\"):\n",
    "    first_line = 0\n",
    "    second_line = 0\n",
    "    third_line = 0\n",
    "\n",
    "    for word in re.sub(r'[^\\w\\s]', '', poem[1]).split() :\n",
    "        all_words.append(word.lower())\n",
    "        first_line += syllapy.count(word)\n",
    "        # record bad words\n",
    "        if syllapy.count(word) == 0 :\n",
    "            invalid_words.append(word)\n",
    "    for word in re.sub(r'[^\\w\\s]', '', poem[2]).split() :\n",
    "        second_line += syllapy.count(word)\n",
    "        all_words.append(word.lower())\n",
    "    for word in re.sub(r'[^\\w\\s]', '', poem[3]).split() :\n",
    "        third_line += syllapy.count(word)\n",
    "        all_words.append(word.lower())\n",
    "    \n",
    "#     print(first_line)\n",
    "#     print(second_line)\n",
    "#     print(third_line)\n",
    "    syllable_counts[poem[0]] = [first_line, second_line, third_line]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "992cd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllable_counts.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da10a3",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "19b32f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums of all syllables\n",
      "First Line: 93189\n",
      "Second Line: 130978\n",
      "Third Line: 93589\n",
      "\n",
      "Minimum number of syllables\n",
      "First Line: 0\n",
      "Second Line: 0\n",
      "Third Line: 0\n",
      "\n",
      "Maximum number of syllables\n",
      "First Line: 8\n",
      "Second Line: 77\n",
      "Third Line: 22\n",
      "\n",
      "Average number of syllables\n",
      "First Line: 5.0102\n",
      "Second Line: 7.0418\n",
      "Third Line: 5.0317\n",
      "\n",
      "Valid Poems\n",
      "11160 out of 19601\n",
      "56.9359% are valid\n",
      "\n",
      "Semi Valid Poems\n",
      "17761 out of 19601\n",
      "90.6127% are semi valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_lines = []\n",
    "second_lines = []\n",
    "third_lines = []\n",
    "\n",
    "valid = 0\n",
    "\n",
    "semi_valid = 0\n",
    "\n",
    "\n",
    "for poem in syllable_counts.items():\n",
    "    first_lines.append(poem[1][0])\n",
    "    second_lines.append(poem[1][1])\n",
    "    third_lines.append(poem[1][2])\n",
    "    # break\n",
    "    # print(type(poem[1][0]))\n",
    "\n",
    "    if poem[1][0] == 5 and \\\n",
    "    poem[1][1] == 7 and \\\n",
    "    poem[1][2] == 5 :\n",
    "        valid = valid + 1\n",
    "        \n",
    "    if poem[1][0] >= 4 and poem[1][0] <= 6 and \\\n",
    "    poem[1][1] >= 6 and poem[1][1] <= 8 and \\\n",
    "    poem[1][2] >= 4 and poem[1][2] <= 6 :\n",
    "        semi_valid = semi_valid + 1\n",
    "    \n",
    "print(\"Sums of all syllables\")\n",
    "print(\"First Line: \"+str(sum(first_lines)))  \n",
    "print(\"Second Line: \"+str(sum(second_lines)))  \n",
    "print(\"Third Line: \"+str(sum(third_lines)))  \n",
    "print()\n",
    "\n",
    "print(\"Minimum number of syllables\")\n",
    "print(\"First Line: \"+str(min(first_lines)))  \n",
    "print(\"Second Line: \"+str(min(second_lines)))  \n",
    "print(\"Third Line: \"+str(min(third_lines)))  \n",
    "print()\n",
    "\n",
    "print(\"Maximum number of syllables\")\n",
    "print(\"First Line: \"+str(max(first_lines)))  \n",
    "print(\"Second Line: \"+str(max(second_lines)))  \n",
    "print(\"Third Line: \"+str(max(third_lines)))  \n",
    "print()\n",
    "\n",
    "print(\"Average number of syllables\")\n",
    "print(\"First Line: \"+str(round(mean(first_lines),4)))  \n",
    "print(\"Second Line: \"+str(round(mean(second_lines),4)))  \n",
    "print(\"Third Line: \"+str(round(mean(third_lines),4)))  \n",
    "print()\n",
    "\n",
    "print(\"Valid Poems\")\n",
    "print( str(valid)+\" out of 19601\" )\n",
    "print( str(100*round(valid/19601,6))+\"% are valid\" )\n",
    "print()\n",
    "\n",
    "print(\"Semi Valid Poems\")\n",
    "print( str(semi_valid)+\" out of 19601\" )\n",
    "print( str(100*round(semi_valid/19601,6))+\"% are semi valid\" )\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dae88d",
   "metadata": {},
   "source": [
    "## Naughty Words\n",
    "\n",
    "Words which did not exist in syllable dictionary, and resulted in possible 0 syllable lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "46dc129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['95', 'NC-17:', \"'40s\", '8th', \"2's\", '13:', '/', '13', '5', '1st', 'MST3K:', '1984:', 'B-52', '486:', '911!']\n"
     ]
    }
   ],
   "source": [
    "print(invalid_words[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0437e",
   "metadata": {},
   "source": [
    "## Most Common Words\n",
    "\n",
    "Using `Counter`, we pulled out the most common words, and then after cleaning the word list of stop words produced a 2nd list of most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f30b1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common All Words\n",
      "[('spam', 15338), ('the', 8381), ('a', 4836), ('i', 4630), ('of', 4357), ('in', 3672), ('and', 3624), ('is', 3146), ('to', 3099), ('my', 3080), ('it', 2924), ('you', 2218), ('can', 2152), ('on', 1881), ('for', 1812), ('pink', 1654), ('with', 1579), ('me', 1365), ('eat', 1308), ('not', 1193)]\n",
      "\n",
      "Most Common Filtered Words\n",
      "[('spam', 15338), ('pink', 1654), ('eat', 1308), ('like', 1100), ('meat', 1070), ('one', 655), ('blue', 605), ('love', 586), ('pig', 578), ('spamku', 507), ('hormel', 503), ('good', 477), ('pork', 473), ('food', 473), ('dont', 463), ('oh', 463), ('new', 390), ('man', 387), ('life', 385), ('haiku', 377)]\n"
     ]
    }
   ],
   "source": [
    "# Pass the split_it list to instance of Counter class.\n",
    "AllWordsCounter = Counter(all_words)\n",
    "  \n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "print(\"Most Common All Words\")\n",
    "print(AllWordsCounter.most_common(20))\n",
    "print()\n",
    "\n",
    "filtered_words = [t for t in all_words if not t in stopwords.words(\"english\")]\n",
    "\n",
    "# Pass the split_it list to instance of Counter class.\n",
    "FilteredWordsCounter = Counter(filtered_words)\n",
    "  \n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "print(\"Most Common Filtered Words\")\n",
    "print(FilteredWordsCounter.most_common(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88bda3",
   "metadata": {},
   "source": [
    "# Sample of Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "80436be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_poem(poem):\n",
    "    print(poem[1])\n",
    "    print(poem[2])\n",
    "    print(poem[3])\n",
    "    print()\n",
    "    \n",
    "def analyze_poem(poem):\n",
    "    counts = [0,0,0,0]\n",
    "    for i in range(1,4):\n",
    "        results = \"\"\n",
    "        line = poem[i]\n",
    "        # print(line)\n",
    "        words = line.split()\n",
    "        count = 0\n",
    "        for word in words :\n",
    "            results = results + word + \"(\" + str(syllapy.count(word)) + \") \"\n",
    "            counts[i] = counts[i] + syllapy.count(word)\n",
    "        print(results + \"=> \" + str(counts[i]))\n",
    "    print()\n",
    "    if counts[1] == 5 and counts[2] == 7 and counts[3] == 5 :\n",
    "        print(\"Valid Haiku\")\n",
    "    elif counts[1] >= 4 and counts[1] <= 6 and \\\n",
    "    counts[2] >= 6 and counts[2] <= 8 and \\\n",
    "    counts[3] >= 4 and counts[3] <= 6:\n",
    "        print(\"Semi Valid Haiku\")\n",
    "    else:\n",
    "        print(\"Invalid Haiku\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "363b6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing on the edge\n",
      "a can of SPAM to my head\n",
      "my taste buds blew up\n",
      "\n",
      "standing(2) on(1) the(1) edge(1) => 5\n",
      "a(1) can(1) of(1) SPAM(1) to(1) my(1) head(1) => 7\n",
      "my(1) taste(1) buds(1) blew(1) up(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Mona Lisa smiles\n",
      "so peaceful and knowingly\n",
      "she before SPAM's time\n",
      "\n",
      "Mona(2) Lisa(2) smiles(2) => 6\n",
      "so(1) peaceful(2) and(1) knowingly(3) => 7\n",
      "she(1) before(2) SPAM's(1) time(1) => 5\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "I know what I want\n",
      "Baked beans and SPAM--what, no beans?\n",
      "I'll have SPAM instead\n",
      "\n",
      "I(1) know(1) what(1) I(1) want(1) => 5\n",
      "Baked(2) beans(1) and(1) SPAM--what,(2) no(1) beans?(1) => 8\n",
      "I'll(1) have(1) SPAM(1) instead(2) => 5\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Dear Hormel people:\n",
      "I'll blow up your factory!\n",
      "--Teddy Kaczynski\n",
      "\n",
      "Dear(1) Hormel(2) people:(2) => 5\n",
      "I'll(1) blow(1) up(1) your(1) factory!(3) => 7\n",
      "--Teddy(2) Kaczynski(3) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "The school lunch ladies\n",
      "used to say, \"Just eat your SPAM\n",
      "and shut the hell up!\"\n",
      "\n",
      "The(1) school(1) lunch(1) ladies(2) => 5\n",
      "used(1) to(1) say,(1) \"Just(1) eat(1) your(1) SPAM(1) => 7\n",
      "and(1) shut(1) the(1) hell(1) up!\"(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Behold the blue can\n",
      "The splendor of its pure form\n",
      "We all worship it\n",
      "\n",
      "Behold(2) the(1) blue(1) can(1) => 5\n",
      "The(1) splendor(2) of(1) its(1) pure(1) form(1) => 7\n",
      "We(1) all(1) worship(2) it(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Frozen block of SPAM\n",
      "Lurking in my freezer like\n",
      "A germy Mars rock.\n",
      "\n",
      "Frozen(2) block(1) of(1) SPAM(1) => 5\n",
      "Lurking(2) in(1) my(1) freezer(2) like(1) => 7\n",
      "A(1) germy(2) Mars(1) rock.(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Why do we do it?\n",
      "Is there something wrong with us\n",
      "neurochemic'lly?\n",
      "\n",
      "Why(1) do(1) we(1) do(1) it?(1) => 5\n",
      "Is(1) there(1) something(2) wrong(1) with(1) us(1) => 7\n",
      "neurochemic'lly?(5) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "In Boston's Back Bay\n",
      "Yuppies closet-eat canned SPAM\n",
      "Then use Binaca\n",
      "\n",
      "In(1) Boston's(2) Back(1) Bay(1) => 5\n",
      "Yuppies(2) closet-eat(3) canned(2) SPAM(1) => 8\n",
      "Then(1) use(1) Binaca(3) => 5\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Dinosaur entrails,\n",
      "Still pulsating...and purple.\n",
      "Yes! It's B'har'nei SPAM!\n",
      "\n",
      "Dinosaur(3) entrails,(2) => 5\n",
      "Still(1) pulsating...and(4) purple.(2) => 7\n",
      "Yes!(1) It's(1) B'har'nei(2) SPAM!(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Marcellus's case,\n",
      "glowing and awe-inspiring--\n",
      "You know what it was!\n",
      "\n",
      "Marcellus's(3) case,(1) => 4\n",
      "glowing(2) and(1) awe-inspiring--(4) => 7\n",
      "You(1) know(1) what(1) it(1) was!(1) => 5\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "SPAM is in the air\n",
      "Many species become one\n",
      "Homogenized gel\n",
      "\n",
      "SPAM(1) is(1) in(1) the(1) air(1) => 5\n",
      "Many(2) species(2) become(2) one(1) => 7\n",
      "Homogenized(5) gel(1) => 6\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Casa de Piggie\n",
      "features Tacos Hormel and\n",
      "SPAM enchiladas.\n",
      "\n",
      "Casa(2) de(1) Piggie(1) => 4\n",
      "features(3) Tacos(2) Hormel(2) and(1) => 8\n",
      "SPAM(1) enchiladas.(4) => 5\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "SPAM for career girls.\n",
      "Bright, shiny, greasy, and pink ...\n",
      "Need to find a sink!!!\n",
      "\n",
      "SPAM(1) for(1) career(2) girls.(1) => 5\n",
      "Bright,(1) shiny,(2) greasy,(2) and(1) pink(1) ...(0) => 7\n",
      "Need(1) to(1) find(1) a(1) sink!!!(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "This delicacy..\n",
      "Known as SPAM.  Fits in my hand.\n",
      "I worship you, SPAM!\n",
      "\n",
      "This(1) delicacy..(4) => 5\n",
      "Known(1) as(1) SPAM.(1) Fits(1) in(1) my(1) hand.(1) => 7\n",
      "I(1) worship(2) you,(1) SPAM!(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "SPAM between the strings.\n",
      "A new Cage composition?\n",
      "No: hog Bacchanale!\n",
      "\n",
      "SPAM(1) between(2) the(1) strings.(1) => 5\n",
      "A(1) new(1) Cage(1) composition?(4) => 7\n",
      "No:(1) hog(1) Bacchanale!(3) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "The SPAM loaf cometh.\n",
      "Our champing jaws salivate.\n",
      "Ah...the scrumptious gel!\n",
      "\n",
      "The(1) SPAM(1) loaf(1) cometh.(2) => 5\n",
      "Our(1) champing(2) jaws(1) salivate.(3) => 7\n",
      "Ah...the(1) scrumptious(2) gel!(1) => 4\n",
      "\n",
      "Semi Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Monica Queen SPAM:\n",
      "She's a good old boy's good girl--\n",
      "Full luscious hot lips.\n",
      "\n",
      "Monica(3) Queen(1) SPAM:(1) => 5\n",
      "She's(1) a(1) good(1) old(1) boy's(1) good(1) girl--(1) => 7\n",
      "Full(1) luscious(2) hot(1) lips.(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Sing a song of SPAM:\n",
      "Glistening Jell-O-like meat.\n",
      "Think of all the fat!\n",
      "\n",
      "Sing(1) a(1) song(1) of(1) SPAM:(1) => 5\n",
      "Glistening(3) Jell-O-like(3) meat.(1) => 7\n",
      "Think(1) of(1) all(1) the(1) fat!(1) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "A SPAMwich a day\n",
      "Keeps the old doctor away\n",
      "Mortician's Hooray\n",
      "\n",
      "A(1) SPAMwich(2) a(1) day(1) => 5\n",
      "Keeps(1) the(1) old(1) doctor(2) away(2) => 7\n",
      "Mortician's(3) Hooray(2) => 5\n",
      "\n",
      "Valid Haiku\n",
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for poem in cur.execute(\"SELECT * FROM poems ORDER BY random() LIMIT 20;\"):\n",
    "    print_poem(poem)\n",
    "    analyze_poem(poem)\n",
    "    print(\"---------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50716788",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Close database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "39033f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
